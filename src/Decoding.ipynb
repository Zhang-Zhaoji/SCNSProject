{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2c4dd8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/friiz/anaconda3/envs/pbl/lib/python3.11/site-packages/oasis/functions.py:13: UserWarning: Could not find cvxpy. Don't worry, you can still use OASIS, just not the slower interior point methods we compared to in the papers.\n",
      "  warn(\"Could not find cvxpy. Don't worry, you can still use OASIS, \" +\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "from load_data import load_data,get_SG_FR, similarity_metric, read_Decoding_csv, load_neural_npz\n",
    "from dataset import LinearRegressionModel, NeuralDataset\n",
    "from oasis.functions import deconvolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71d8e39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have keys in data_dict, including:\n",
      "stimulus_metadata_drifting_gratings.csv\n",
      "stimulus_metadata_natural_movie_one.csv\n",
      "stimulus_metadata_natural_movie_three.csv\n",
      "stimulus_metadata_spontaneous.csv\n",
      "we have keys in data_dict, including:\n",
      "stimulus_metadata_natural_movie_one.csv\n",
      "stimulus_metadata_natural_scenes.csv\n",
      "stimulus_metadata_spontaneous.csv\n",
      "stimulus_metadata_static_gratings.csv\n",
      "stimulus_metadata_total.csv\n",
      "================================================\n",
      "['VISp_three_session_A_501704220', 'VISp_three_session_B_501559087']\n",
      "check subtitles, should be ['ts', 'dff', 'all_roi_masks', 'cids', 'metadata']\n",
      "['ts', 'dff', 'all_roi_masks', 'cids', 'metadata']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 142/142 [00:37<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================\n",
      "Caution, the position of this file is about the brain part of VISp\n",
      "================================================\n",
      "check subtitles, should be ['ts', 'dff', 'all_roi_masks', 'cids', 'metadata']\n",
      "['ts', 'dff', 'all_roi_masks', 'cids', 'metadata']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 174/174 [00:48<00:00,  3.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================\n",
      "Caution, the position of this file is about the brain part of VISp\n",
      "================================================\n",
      "================================================\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "Target_Brain_region = 'VISp'\n",
    "data_root = '../data'\n",
    "sessions = ['A','B']\n",
    "session_datas = []\n",
    "session_folders = [] \n",
    "for session in sessions:\n",
    "    tgt_dict, tgt_folder = read_Decoding_csv(data_path='../data',region_type = Target_Brain_region, session_letter = session)\n",
    "    session_datas.append(tgt_dict)\n",
    "    session_folders.append(tgt_folder)\n",
    "print('================================================')\n",
    "print(session_folders)\n",
    "\n",
    "ts_sessions = []\n",
    "dff_sessions = []\n",
    "all_roi_masks_sessions = []\n",
    "cids_sessions = []\n",
    "metadata_sessions = []\n",
    "spike_info_sessions = []\n",
    "\n",
    "for tgt_data_path in session_folders:\n",
    "    for file_name in os.listdir(os.path.join(data_root, tgt_data_path)):\n",
    "        if file_name.endswith('.npz'):\n",
    "            ts, dff, all_roi_masks, cids, metadata = load_neural_npz(os.path.join(data_root, tgt_data_path,file_name))\n",
    "            ts_sessions.append(ts)\n",
    "            dff_sessions.append(dff)\n",
    "            all_roi_masks_sessions.append(all_roi_masks)\n",
    "            cids_sessions.append(cids)\n",
    "            metadata_sessions.append(metadata)\n",
    "            spike_info_sessions.append(np.array([deconvolve(dff[_i,:], penalty=1)[1] for _i in trange(dff.shape[0])]))\n",
    "            position = metadata.tolist()\n",
    "            print('================================================')\n",
    "            print('Caution, the position of this file is about the brain part of', position['targeted_structure'])\n",
    "            print('================================================')\n",
    "print('================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38363b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'stimulus_metadata_drifting_gratings.csv':      Unnamed: 0  temporal_frequency  orientation  blank_sweep   start     end\n",
      "0             0                 8.0        270.0          0.0     747     807\n",
      "1             1                 2.0        135.0          0.0     837     897\n",
      "2             2                 2.0        315.0          0.0     927     987\n",
      "3             3                15.0        315.0          0.0    1018    1077\n",
      "4             4                 1.0        270.0          0.0    1108    1168\n",
      "..          ...                 ...          ...          ...     ...     ...\n",
      "623         623                 4.0        270.0          0.0  114837  114897\n",
      "624         624                 4.0        180.0          0.0  114928  114987\n",
      "625         625                 2.0        180.0          0.0  115018  115078\n",
      "626         626                 8.0        270.0          0.0  115108  115168\n",
      "627         627                 4.0          0.0          0.0  115198  115258\n",
      "\n",
      "[628 rows x 6 columns], 'stimulus_metadata_natural_movie_one.csv':       Unnamed: 0  frame  start    end  repeat\n",
      "0              0      0  38682  38682       0\n",
      "1              1      1  38683  38683       0\n",
      "2              2      2  38684  38684       0\n",
      "3              3      3  38685  38685       0\n",
      "4              4      4  38686  38686       0\n",
      "...          ...    ...    ...    ...     ...\n",
      "8995        8995    895  47710  47711       9\n",
      "8996        8996    896  47711  47712       9\n",
      "8997        8997    897  47712  47713       9\n",
      "8998        8998    898  47713  47714       9\n",
      "8999        8999    899  47714  47715       9\n",
      "\n",
      "[9000 rows x 5 columns], 'stimulus_metadata_natural_movie_three.csv':        Unnamed: 0  frame  start    end  repeat\n",
      "0               0      0  19714  19715       0\n",
      "1               1      1  19715  19716       0\n",
      "2               2      2  19716  19717       0\n",
      "3               3      3  19717  19718       0\n",
      "4               4      4  19718  19719       0\n",
      "...           ...    ...    ...    ...     ...\n",
      "35995       35995   3595  93769  93770       9\n",
      "35996       35996   3596  93770  93771       9\n",
      "35997       35997   3597  93771  93772       9\n",
      "35998       35998   3598  93772  93773       9\n",
      "35999       35999   3599  93773  93774       9\n",
      "\n",
      "[36000 rows x 5 columns], 'stimulus_metadata_spontaneous.csv':    Unnamed: 0  start    end\n",
      "0           0  66800  75711}, {'stimulus_metadata_natural_movie_one.csv':       Unnamed: 0  frame  start    end  repeat\n",
      "0              0      0  70307  70307       0\n",
      "1              1      1  70308  70308       0\n",
      "2              2      2  70309  70309       0\n",
      "3              3      3  70310  70310       0\n",
      "4              4      4  70311  70311       0\n",
      "...          ...    ...    ...    ...     ...\n",
      "8995        8995    895  79333  79334       9\n",
      "8996        8996    896  79334  79335       9\n",
      "8997        8997    897  79335  79336       9\n",
      "8998        8998    898  79336  79337       9\n",
      "8999        8999    899  79337  79338       9\n",
      "\n",
      "[9000 rows x 5 columns], 'stimulus_metadata_natural_scenes.csv':       Unnamed: 0  frame  start    end\n",
      "0              0     81  16100  16107\n",
      "1              1     33  16108  16115\n",
      "2              2     76  16115  16122\n",
      "3              3     13  16123  16130\n",
      "4              4     56  16130  16137\n",
      "...          ...    ...    ...    ...\n",
      "5945        5945     48  96089  96096\n",
      "5946        5946      3  96097  96104\n",
      "5947        5947     34  96104  96111\n",
      "5948        5948     -1  96112  96119\n",
      "5949        5949     87  96119  96126\n",
      "\n",
      "[5950 rows x 4 columns], 'stimulus_metadata_spontaneous.csv':    Unnamed: 0  start    end\n",
      "0           0  30701  39581, 'stimulus_metadata_static_gratings.csv':       Unnamed: 0  orientation  spatial_frequency  phase   start     end\n",
      "0              0         90.0               0.04   0.50     747     754\n",
      "1              1        150.0               0.04   0.50     754     761\n",
      "2              2         30.0               0.02   0.00     762     769\n",
      "3              3          0.0               0.32   0.50     769     776\n",
      "4              4        150.0               0.16   0.75     777     784\n",
      "...          ...          ...                ...    ...     ...     ...\n",
      "5995        5995          0.0               0.04   0.50  113625  113632\n",
      "5996        5996         30.0               0.02   0.25  113632  113639\n",
      "5997        5997          0.0               0.32   0.25  113640  113647\n",
      "5998        5998          0.0               0.04   0.75  113647  113654\n",
      "5999        5999         30.0               0.02   0.00  113655  113662\n",
      "\n",
      "[6000 rows x 6 columns], 'stimulus_metadata_total.csv':       Unnamed: 0  orientation  spatial_frequency  phase   start     end\n",
      "0              0          0.0               0.16   0.50     745     752\n",
      "1              1         90.0               0.16   0.75     752     759\n",
      "2              2         90.0               0.16   0.00     760     767\n",
      "3              3         60.0               0.04   0.50     767     774\n",
      "4              4          NaN                NaN    NaN     775     782\n",
      "...          ...          ...                ...    ...     ...     ...\n",
      "5995        5995         60.0               0.04   0.00  113599  113606\n",
      "5996        5996         90.0               0.32   0.00  113607  113614\n",
      "5997        5997         60.0               0.04   0.75  113614  113621\n",
      "5998        5998        120.0               0.04   0.25  113622  113629\n",
      "5999        5999          0.0               0.32   0.25  113629  113636\n",
      "\n",
      "[6000 rows x 6 columns]}]\n"
     ]
    }
   ],
   "source": [
    "print(session_datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90c42078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======= 处理脑区: VISp =======\n",
      "we have keys in data_dict, including:\n",
      "stimulus_metadata_drifting_gratings.csv\n",
      "stimulus_metadata_natural_movie_one.csv\n",
      "stimulus_metadata_natural_movie_three.csv\n",
      "stimulus_metadata_spontaneous.csv\n",
      "check subtitles, should be ['ts', 'dff', 'all_roi_masks', 'cids', 'metadata']\n",
      "['ts', 'dff', 'all_roi_masks', 'cids', 'metadata']\n",
      "警告: 脑区 VISp 只有 1 类刺激，无法分类\n",
      "\n",
      "======= 分类结果比较 =======\n",
      "VISp脑区: 没有足够的刺激类型进行分类\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import trange\n",
    "\n",
    "# 定义目标脑区\n",
    "target_brain_regions = ['VISp']#, 'VISal', 'VISl']\n",
    "session_letter = 'A'  # 使用session A进行分析\n",
    "data_root = '../data'\n",
    "\n",
    "# 存储每个脑区的分类结果\n",
    "results = {}\n",
    "\n",
    "for region in target_brain_regions:\n",
    "    print(f\"\\n======= 处理脑区: {region} =======\")\n",
    "    \n",
    "    # 1. 读取元数据\n",
    "    tgt_dict, tgt_folder = read_Decoding_csv(data_path=data_root, \n",
    "                                            region_type=region, \n",
    "                                            session_letter=session_letter)\n",
    "    \n",
    "    # 2. 加载神经活动数据\n",
    "    neural_file_path = os.path.join(data_root, tgt_folder)\n",
    "    for file_name in os.listdir(neural_file_path):\n",
    "        if file_name.endswith('.npz'):\n",
    "            ts, dff, all_roi_masks, cids, metadata = load_neural_npz(\n",
    "                os.path.join(neural_file_path, file_name))\n",
    "            break  # 假设每个文件夹只有一个npz文件\n",
    "    \n",
    "    # 3. 提取刺激时间段和创建标签\n",
    "    stimulus_data = []\n",
    "    stimulus_labels = []\n",
    "    stimulus_types = []\n",
    "    \n",
    "    # 定义刺激类型映射\n",
    "    stim_type_mapping = {\n",
    "        'drifting_gratings': 0,\n",
    "        'static_gratings': 1,\n",
    "        'natural_scenes': 2,\n",
    "        'natural_movie': 3  # 包括natural_movie_one和three\n",
    "    }\n",
    "    \n",
    "    # 处理每种刺激类型\n",
    "    for stim_key, stim_df in tgt_dict.items():\n",
    "        if 'drifting_gratings' in stim_key:\n",
    "            stim_type = 'drifting_gratings'\n",
    "        elif 'static_gratings' in stim_key:\n",
    "            stim_type = 'static_gratings'\n",
    "        elif 'natural_scenes' in stim_key:\n",
    "            stim_type = 'natural_scenes'\n",
    "        elif 'natural_movie' in stim_key:  # 包括one和three\n",
    "            stim_type = 'natural_movie'\n",
    "        else:\n",
    "            continue  # 跳过其他刺激类型\n",
    "        \n",
    "        # 获取刺激开始和结束时间\n",
    "        for _, row in stim_df.iterrows():\n",
    "            start_time = row['start']\n",
    "            end_time = row['end']\n",
    "            \n",
    "            # 找到对应时间段的神经活动索引\n",
    "            time_indices = np.where((ts >= start_time) & (ts <= end_time))[0]\n",
    "            \n",
    "            if len(time_indices) > 0:\n",
    "                # 计算该时间段内所有神经元的平均活动\n",
    "                neural_activity = np.mean(dff[:, time_indices], axis=1)\n",
    "                stimulus_data.append(neural_activity)\n",
    "                stimulus_labels.append(stim_type_mapping[stim_type])\n",
    "                stimulus_types.append(stim_type)\n",
    "    \n",
    "    # 4. 准备分类数据\n",
    "    X = np.array(stimulus_data)\n",
    "    y = np.array(stimulus_labels)\n",
    "    \n",
    "    # 检查是否有足够样本\n",
    "    if len(np.unique(y)) < 2:\n",
    "        print(f\"警告: 脑区 {region} 只有 {len(np.unique(y))} 类刺激，无法分类\")\n",
    "        results[region] = {'accuracy': None, 'classes': np.unique(y)}\n",
    "        continue\n",
    "    \n",
    "    # 5. 数据预处理\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # 6. 划分训练集和测试集\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=0.3, random_state=42, stratify=y)\n",
    "    \n",
    "    # 7. 训练分类器\n",
    "    classifier = LogisticRegression(max_iter=1000, multi_class='ovr')\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # 8. 评估性能\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # 9. 保存结果\n",
    "    results[region] = {\n",
    "        'accuracy': accuracy,\n",
    "        'num_samples': len(y),\n",
    "        'classes': np.unique(y),\n",
    "        'class_names': [k for k, v in stim_type_mapping.items() if v in np.unique(y)]\n",
    "    }\n",
    "    print(f\"脑区 {region} 分类准确率: {accuracy:.4f}\")\n",
    "    print(f\"使用的刺激类型: {results[region]['class_names']}\")\n",
    "\n",
    "# 10. 比较三个脑区的性能\n",
    "print(\"\\n======= 分类结果比较 =======\")\n",
    "for region, res in results.items():\n",
    "    if res['accuracy'] is not None:\n",
    "        print(f\"{region}脑区: 准确率={res['accuracy']:.4f}, 样本数={res['num_samples']}, 刺激类型={res['class_names']}\")\n",
    "    else:\n",
    "        print(f\"{region}脑区: 没有足够的刺激类型进行分类\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pbl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
